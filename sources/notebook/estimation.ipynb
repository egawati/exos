{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.linalg import eig\n",
    "from numpy.linalg import svd\n",
    "from numpy.linalg import qr\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA using covariance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.shape (3, 5)\n",
      "[[45 37 42 35 39]\n",
      " [38 31 26 28 33]\n",
      " [10 15 17 21 12]]\n"
     ]
    }
   ],
   "source": [
    "#covariance\n",
    "x = [45,37,42,35,39]\n",
    "y = [38,31,26,28,33]\n",
    "z = [10,15,17,21,12]\n",
    "data = np.array([x,y,z])\n",
    "print(f'data.shape {data.shape}')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A.shape (3, 5)\n",
      "M.shape (3,)\n",
      "C.shape (5, 3)\n",
      "(3, 3)\n",
      "Eigen vectors (3, 3)\n",
      "Principal Component (2, 5)\n",
      "A_estimate (3, 5)\n",
      "[[44.8764548  37.00207673 42.06499339 35.11406186 38.94241323]\n",
      " [34.96690144 31.05098469 27.59562124 30.8002777  31.58621493]\n",
      " [16.78103539 14.88601459 13.43270278 14.73947736 15.16076988]]\n"
     ]
    }
   ],
   "source": [
    "# define a matrix\n",
    "A = data\n",
    "print(f'A.shape {A.shape}')\n",
    "# calculate the mean of each row\n",
    "M = np.mean(A, axis=1)\n",
    "print(f'M.shape {M.shape}')\n",
    "# center columns by subtracting column means\n",
    "C = A.T - M\n",
    "print(f'C.shape {C.shape}')\n",
    "# calculate covariance matrix of centered matrix\n",
    "V = A.dot(A.T)/(A.shape[0]-1)\n",
    "print(V.shape)\n",
    "#eigendecomposition of covariance matrix\n",
    "values, vectors = eig(V)\n",
    "print(f'Eigen vectors {vectors.shape}')\n",
    "\n",
    "# project data\n",
    "k = 2\n",
    "P = vectors[:,0:k].T.dot(C.T)\n",
    "print(f'Principal Component {P.shape}')\n",
    "A_estimate = vectors[:,0:k].dot(P)\n",
    "print(f'A_estimate {A_estimate.shape}')\n",
    "print((A_estimate.T + M).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A.shape (3, 5)\n",
      "M.shape (3,)\n",
      "C.shape (5, 3)\n",
      "(3, 3)\n",
      "Eigen vectors (3, 3)\n",
      "Principal Component (3, 5)\n",
      "[[45. 37. 42. 35. 39.]\n",
      " [38. 31. 26. 28. 33.]\n",
      " [10. 15. 17. 21. 12.]]\n"
     ]
    }
   ],
   "source": [
    "# define a matrix\n",
    "A = data\n",
    "print(f'A.shape {A.shape}')\n",
    "# calculate the mean of each row\n",
    "M = np.mean(A, axis=1)\n",
    "print(f'M.shape {M.shape}')\n",
    "# center columns by subtracting column means\n",
    "C = A.T - M\n",
    "print(f'C.shape {C.shape}')\n",
    "# calculate covariance matrix of centered matrix\n",
    "V = np.cov(C.T)\n",
    "print(V.shape)\n",
    "#eigendecomposition of covariance matrix\n",
    "values, vectors = eig(V)\n",
    "print(f'Eigen vectors {vectors.shape}')\n",
    "\n",
    "# project data\n",
    "k = 3\n",
    "P = vectors[:,0:k].T.dot(C.T)\n",
    "print(f'Principal Component {P.shape}')\n",
    "A_estimate = vectors[:,0:k].dot(P)\n",
    "print((A_estimate.T + M).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A.shape (5, 3)\n",
      "M.shape (3,)\n",
      "C.shape (5, 3)\n",
      "(3, 3)\n",
      "Eigen vectors (3, 3)\n",
      "Principal Component (3, 5)\n",
      "[[45. 37. 42. 35. 39.]\n",
      " [38. 31. 26. 28. 33.]\n",
      " [10. 15. 17. 21. 12.]]\n"
     ]
    }
   ],
   "source": [
    "# define a matrix\n",
    "A = data.T\n",
    "print(f'A.shape {A.shape}')\n",
    "# calculate the mean of each column\n",
    "M = np.mean(A, axis=0)\n",
    "print(f'M.shape {M.shape}')\n",
    "# center columns by subtracting column means\n",
    "C = A - M\n",
    "print(f'C.shape {C.shape}')\n",
    "# calculate covariance matrix of centered matrix\n",
    "V = np.cov(C.T)\n",
    "print(V.shape)\n",
    "#eigendecomposition of covariance matrix\n",
    "values, vectors = eig(V)\n",
    "print(f'Eigen vectors {vectors.shape}')\n",
    "\n",
    "# project data\n",
    "k = 3\n",
    "P = vectors[:,0:k].T.dot(C.T)\n",
    "print(f'Principal Component {P.shape}')\n",
    "A_estimate = vectors[:,0:k].dot(P)\n",
    "print((A_estimate.T + M).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_reconstruction(cov, C, variance_explained=1):\n",
    "    eig_values, eig_vectors = eig(cov)\n",
    "    k = len(eig_values)\n",
    "    if variance_explained != 1:\n",
    "        trace = sum(eig_values)\n",
    "        var_explained = 0\n",
    "        for i, val in enumerate(eig_values):\n",
    "            var_explained += val/trace\n",
    "            print(f'{i} - {var_explained}')\n",
    "            if var_explained >= variance_explained:\n",
    "                k = i\n",
    "    Y = eig_vectors[:,0:k].T.dot(C.T)\n",
    "    C_estimate = eig_vectors[:,0:k].dot(Y)\n",
    "    return C_estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1 -1]\n",
      " [-2 -1]\n",
      " [-3 -2]\n",
      " [ 1  1]\n",
      " [ 2  1]\n",
      " [ 3  2]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1., -1.],\n",
       "       [-2., -1.],\n",
       "       [-3., -2.],\n",
       "       [ 1.,  1.],\n",
       "       [ 2.,  1.],\n",
       "       [ 3.,  2.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\n",
    "print(X)\n",
    "M = np.mean(X, axis=0)\n",
    "C = X - M\n",
    "cov = np.cov(C.T)\n",
    "C_estimate = pca_reconstruction(cov, C, variance_explained=1)\n",
    "X_estimate = C_estimate.T + M\n",
    "X_estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - 0.9924428900898052\n",
      "1 - 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.15997501, -0.75383654],\n",
       "       [-1.86304424, -1.21074232],\n",
       "       [-3.02301925, -1.96457886],\n",
       "       [ 1.15997501,  0.75383654],\n",
       "       [ 1.86304424,  1.21074232],\n",
       "       [ 3.02301925,  1.96457886]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_estimate = pca_reconstruction(cov, C, variance_explained=0.9)\n",
    "X_estimate = C_estimate.T + M\n",
    "X_estimate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA using SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.shape (3, 5)\n",
      "U.shape (3, 3)\n",
      "S.shape (3,)\n",
      "V.shape (3, 3)\n"
     ]
    }
   ],
   "source": [
    "U, S, Vt = np.linalg.svd(data, full_matrices=False)\n",
    "print(f'data.shape {data.shape}')\n",
    "print(f'U.shape {U.shape}')\n",
    "print(f'S.shape {S.shape}')\n",
    "print(f'V.shape {V.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[45 37 42 35 39]\n",
      " [38 31 26 28 33]\n",
      " [10 15 17 21 12]]\n",
      "data from svd[[45. 37. 42. 35. 39.]\n",
      " [38. 31. 26. 28. 33.]\n",
      " [10. 15. 17. 21. 12.]]\n"
     ]
    }
   ],
   "source": [
    "print(data)\n",
    "print(f'data from svd{np.dot(U*S, Vt)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[44.81347318, 38.06162501, 39.01822428, 36.73429164, 39.52092306],\n",
       "       [38.19652839, 29.88145062, 29.14165864, 26.17271558, 32.45114502],\n",
       "       [10.08450708, 14.51902451, 18.35091114, 20.21426891, 11.76399272]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 2\n",
    "data_estimate = np.dot(U[:,0:k]*S[0:k], Vt[0:k, :])\n",
    "data_estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svd_reconstruction(U, S, Vt, variance_explained=1):\n",
    "    if variance_explained == 1:\n",
    "        A_estimate = np.dot(U*S, Vt)\n",
    "    else:\n",
    "        var_explained = 0\n",
    "        trace = sum(S)\n",
    "        for i, val in enumerate(S):\n",
    "            var_explained += val/trace\n",
    "            if var_explained >= variance_explained:\n",
    "                k = i\n",
    "        A_estimate = np.dot(U[:,0:k]*S[0:k], Vt[0:k, :])\n",
    "    return A_estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[45. 37. 42. 35. 39.]\n",
      " [38. 31. 26. 28. 33.]\n",
      " [10. 15. 17. 21. 12.]]\n"
     ]
    }
   ],
   "source": [
    "print(svd_reconstruction(U, S, Vt, variance_explained=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[44.81347318 38.06162501 39.01822428 36.73429164 39.52092306]\n",
      " [38.19652839 29.88145062 29.14165864 26.17271558 32.45114502]\n",
      " [10.08450708 14.51902451 18.35091114 20.21426891 11.76399272]]\n"
     ]
    }
   ],
   "source": [
    "print(svd_reconstruction(U, S, Vt, variance_explained=0.9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INCREMENTAL PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def incremental_pca(U, S, npoints, acc_mean, new_matrix):\n",
    "    new_matrix_mean = np.mean(new_matrix, axis=1)\n",
    "    Best = (new_matrix.T - new_matrix_mean).T * np.sqrt((npoints + new_matrix.shape[1])/(npoints * new_matrix.shape[1]))* (new_matrix_mean - acc_mean)  \n",
    "    acc_mean = (npoints/(npoints + new_matrix.shape[1])) * acc_mean + (new_matrix.shape[1]/(npoints + new_matrix.shape[1]))*new_matrix_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A \n",
      "[[45 37 42 35 39]\n",
      " [38 31 26 28 33]\n",
      " [10 15 17 21 12]]\n",
      "A.shape (3, 5)\n",
      "U.shape (3, 3)\n",
      "S.shape (3,)\n",
      "V.shape (3, 3)\n",
      "acc_mean \n",
      "[39.6 31.2 15. ]\n",
      "B \n",
      "[[40 38 42 39]\n",
      " [39 28 23 25]\n",
      " [11 12 13 15]]\n",
      "B.shape (3, 4)\n",
      "new_matrix_mean.shape (3,)\n",
      "new_matrix_mean \n",
      "[39.75 28.75 12.75]\n",
      "Best \n",
      "[[  0.02515576  -0.17609035   0.22640188  -0.07546729]\n",
      " [-16.84597713   1.23263247   9.45018229   6.16316236]\n",
      " [  2.6413553    1.13200941  -0.37733647  -3.39602824]]\n",
      "Best.shape (3, 4)\n",
      "q \n",
      "(3, 3)\n",
      "r \n",
      "(3, 4)\n"
     ]
    }
   ],
   "source": [
    "A = data\n",
    "print(f'A \\n{A}')\n",
    "print(f'A.shape {A.shape}')\n",
    "print(f'U.shape {U.shape}')\n",
    "print(f'S.shape {S.shape}')\n",
    "print(f'V.shape {V.shape}')\n",
    "\n",
    "x = [40, 38, 42, 39]\n",
    "y = [39, 28, 23, 25]\n",
    "z = [11, 12, 13, 15]\n",
    "B = np.array([x,y,z])\n",
    "\n",
    "acc_mean = np.mean(A, axis=1)\n",
    "print(f'acc_mean \\n{acc_mean}')\n",
    "print(f'B \\n{B}')\n",
    "print(f'B.shape {B.shape}')\n",
    "new_matrix_mean = np.mean(B, axis=1)\n",
    "print(f'new_matrix_mean.shape {new_matrix_mean.shape}')\n",
    "print(f'new_matrix_mean \\n{new_matrix_mean}')\n",
    "\n",
    "npoints = A.shape[1]\n",
    "Best = (B.T - new_matrix_mean) * np.sqrt((npoints + B.shape[1])/(npoints * B.shape[1])) * (new_matrix_mean - acc_mean)\n",
    "Best = Best.T\n",
    "print(f'Best \\n{Best}')\n",
    "print(f'Best.shape {Best.shape}')\n",
    "\n",
    "q, r = qr(Best - np.dot(np.dot(U, U.T), Best))\n",
    "print(f'q \\n{q.shape}')\n",
    "print(f'r \\n{r.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A.shape (5, 3)\n",
      "A \n",
      "[[3.76405235 2.40015721 2.97873798]\n",
      " [4.2408932  3.86755799 1.02272212]\n",
      " [2.95008842 1.84864279 1.89678115]\n",
      " [2.4105985  2.14404357 3.45427351]\n",
      " [2.76103773 2.12167502 2.44386323]]\n",
      "pca.singular_values_ \n",
      "[2.59757554 1.11936464 0.66182766]\n",
      "pca.components_ [[-0.51356804 -0.55749392  0.65226405]\n",
      " [ 0.46282974  0.46011835  0.75768049]\n",
      " [ 0.72252093 -0.69100769 -0.02172268]]\n",
      "pca.explained_variance_ [1.68684967 0.3132443  0.10950396]\n",
      "pca.explained_variance_ratio_ [0.79960719 0.14848531 0.0519075 ]\n",
      "pca.n_samples_seen_ 5\n",
      "B.shape (7, 3)\n",
      "B \n",
      "[[5.33367433 6.49407907 4.79484174]\n",
      " [5.3130677  4.14590426 2.44701018]\n",
      " [5.6536186  5.8644362  4.25783498]\n",
      " [7.26975462 3.54563433 5.04575852]\n",
      " [4.81281615 6.53277921 6.46935877]\n",
      " [5.15494743 5.37816252 4.11221425]\n",
      " [3.01920353 4.65208785 5.15634897]]\n",
      "pca.singular_values_ \n",
      "[7.7034119  3.90541681 2.98650435]\n",
      "pca.components_ [[ 0.45437679  0.68754006  0.56641893]\n",
      " [ 0.79520316 -0.02647888 -0.60576465]\n",
      " [-0.40148933  0.72566351 -0.55876541]]\n",
      "pca.explained_variance_ [5.39477772 1.38657095 0.81083711]\n",
      "pca.explained_variance_ratio_ [0.71056977 0.18263133 0.1067989 ]\n",
      "pca.n_samples_seen_ 12\n",
      "C reconstruction\n",
      "[[ 6.8132918   8.76887478  2.68699646]\n",
      " [ 8.98215843  7.6384575   3.16114263]\n",
      " [ 6.4392736   7.43870885  3.16459988]\n",
      " [ 5.80372898  8.19018142  1.80980637]\n",
      " [ 6.35084182  7.69849685  2.58643417]\n",
      " [10.0528449  11.05753054  0.08133095]\n",
      " [ 9.11883501  9.401804    2.80398733]\n",
      " [ 9.91312863 10.90449107  0.94402963]\n",
      " [ 8.48720187 12.64881597  2.82382345]\n",
      " [ 9.17465279 11.91353085 -1.17279836]\n",
      " [ 9.35832283 10.46883899  1.03750808]\n",
      " [ 7.39130457  9.77734562 -0.31581369]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA, IncrementalPCA\n",
    "rng = np.random.RandomState(0)\n",
    "A = rng.randn(5, 3) + 2\n",
    "B = rng.randn(7, 3) + 5\n",
    "\n",
    "print(f'A.shape {A.shape}')\n",
    "print(f'A \\n{A}')\n",
    "\n",
    "pca = IncrementalPCA()\n",
    "pca.partial_fit(A)\n",
    "print(f'pca.singular_values_ \\n{pca.singular_values_}')\n",
    "print(f'pca.components_ {pca.components_}')\n",
    "print(f'pca.explained_variance_ {pca.explained_variance_}')\n",
    "print(f'pca.explained_variance_ratio_ {pca.explained_variance_ratio_}')\n",
    "print(f'pca.n_samples_seen_ {pca.n_samples_seen_}')\n",
    "\n",
    "print(f'B.shape {B.shape}')\n",
    "print(f'B \\n{B}')\n",
    "pca.partial_fit(B)\n",
    "print(f'pca.singular_values_ \\n{pca.singular_values_}')\n",
    "print(f'pca.components_ {pca.components_}')\n",
    "print(f'pca.explained_variance_ {pca.explained_variance_}')\n",
    "print(f'pca.explained_variance_ratio_ {pca.explained_variance_ratio_}')\n",
    "print(f'pca.n_samples_seen_ {pca.n_samples_seen_}')\n",
    "\n",
    "C = np.vstack((A,B))\n",
    "print('C reconstruction')\n",
    "print(f'{pca.inverse_transform(C)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test that fit and partial_fit get equivalent results.\n",
    "rng = np.random.RandomState(1999)\n",
    "n, p = 50, 3\n",
    "X = rng.randn(n, p)  # spherical data\n",
    "X[:, 1] *= .00001  # make middle component relatively small\n",
    "X += [5, 4, 3]  # make a large mean\n",
    "\n",
    "# same check that we can find the original data from the transformed\n",
    "# signal (since the data is almost of rank n_components)\n",
    "batch_size = 10\n",
    "ipca = IncrementalPCA(n_components=2, batch_size=batch_size).fit(X)\n",
    "pipca = IncrementalPCA(n_components=2, batch_size=batch_size)\n",
    "# Add one to make sure endpoint is included\n",
    "batch_itr = np.arange(0, n + 1, batch_size)\n",
    "for i, j in zip(batch_itr[:-1], batch_itr[1:]):\n",
    "    pipca.partial_fit(X[i:j, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.61191039e-01, -4.92468531e-07,  6.48527719e-01],\n",
       "       [-6.48527719e-01, -2.06078051e-06,  7.61191039e-01]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipca.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.61191039e-01, -4.92468531e-07,  6.48527719e-01],\n",
       "       [-6.48527719e-01, -2.06078051e-06,  7.61191039e-01]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipca.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A.shape (5, 3)\n",
      "A \n",
      "[[3.76405235 2.40015721 2.97873798]\n",
      " [4.2408932  3.86755799 1.02272212]\n",
      " [2.95008842 1.84864279 1.89678115]\n",
      " [2.4105985  2.14404357 3.45427351]\n",
      " [2.76103773 2.12167502 2.44386323]]\n",
      "pca.singular_values_ \n",
      "[2.59757554 1.11936464]\n",
      "pca.components_ [[-0.51356804 -0.55749392  0.65226405]\n",
      " [ 0.46282974  0.46011835  0.75768049]]\n",
      "pca.explained_variance_ [1.68684967 0.3132443 ]\n",
      "pca.explained_variance_ratio_ [0.79960719 0.14848531]\n",
      "pca.n_samples_seen_ 5\n",
      "a.shape (5, 2)\n",
      "a \n",
      "[[ 0.16989797  0.68360167]\n",
      " [-2.1688981   0.09744077]\n",
      " [ 0.18966821 -0.76666454]\n",
      " [ 1.31794514  0.29964437]\n",
      " [ 0.49138678 -0.31402227]]\n",
      "A reconstruction\n",
      "[[3.45447105 2.6962359  2.98804559]\n",
      " [4.38430928 3.7303971  1.0184103 ]\n",
      " [2.77309135 2.01792001 1.90210259]\n",
      " [2.68716386 1.8795408  3.44595853]\n",
      " [2.82763464 2.05798277 2.44186099]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA, IncrementalPCA\n",
    "rng = np.random.RandomState(0)\n",
    "A = rng.randn(5, 3) + 2\n",
    "B = rng.randn(7, 3) + 5\n",
    "\n",
    "print(f'A.shape {A.shape}')\n",
    "print(f'A \\n{A}')\n",
    "\n",
    "pca = IncrementalPCA(n_components=2)\n",
    "pca.partial_fit(A)\n",
    "print(f'pca.singular_values_ \\n{pca.singular_values_}')\n",
    "print(f'pca.components_ {pca.components_}')\n",
    "print(f'pca.explained_variance_ {pca.explained_variance_}')\n",
    "print(f'pca.explained_variance_ratio_ {pca.explained_variance_ratio_}')\n",
    "print(f'pca.n_samples_seen_ {pca.n_samples_seen_}')\n",
    "\n",
    "##a is the projection of A in k dimension\n",
    "##a: ndarray of shape (n_samples, n_components)\n",
    "a = pca.transform(A)\n",
    "print(f'a.shape {a.shape}')\n",
    "print(f'a \\n{a}')\n",
    "print('A reconstruction')\n",
    "print(f'{pca.inverse_transform(a)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_incremental_pca(X, pca, variance_explained=0.9):\n",
    "    pca.partial_fit(X)\n",
    "    #Y is the projection of X on k dimension\n",
    "    Y = pca.transform(X)\n",
    "    k = 1\n",
    "    # check how many principal components we need based on the explained variance\n",
    "    if variance_explained != 1:\n",
    "        var_explained = 0\n",
    "        for i, val in enumerate(pca.explained_variance_ratio_):\n",
    "            var_explained += val\n",
    "            if var_explained >= variance_explained:\n",
    "                k = i\n",
    "    # to reconstruct X, we use the formula X=YW\n",
    "    X_estimate = np.dot(Y[:,0:k],pca.components_[0:k,:]) + np.mean(X, axis=0)\n",
    "    return(X_estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A.shape (5, 3)\n",
      "A \n",
      "[[3.23029068 3.20237985 1.61267318]\n",
      " [1.69769725 0.95144703 0.57998206]\n",
      " [0.29372981 3.9507754  1.49034782]\n",
      " [1.5619257  0.74720464 2.77749036]\n",
      " [0.38610215 1.78725972 1.10453344]]\n",
      "A_estimate \n",
      "[[3.21132916 3.21086153 1.72715355]\n",
      " [1.52710463 1.02775484 1.60993654]\n",
      " [0.34203728 3.92916698 1.19869105]\n",
      " [1.74488744 0.665364   1.67285718]\n",
      " [0.34438709 1.80591929 1.35638854]]\n"
     ]
    }
   ],
   "source": [
    "A = rng.randn(5, 3) + 2\n",
    "print(f'A.shape {A.shape}')\n",
    "print(f'A \\n{A}')\n",
    "pca = IncrementalPCA()\n",
    "A_estimate = reconstruct_incremental_pca(A, pca, variance_explained=0.9)\n",
    "print(f'A_estimate \\n{A_estimate}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPIRIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3\n",
    "k = 3\n",
    "W = np.zeros((n,k))\n",
    "W[0,0] = 1\n",
    "print\n",
    "d = 0.01 *np.ones(n)\n",
    "lamda =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xt.shape (3,)\n",
      "yi.shape ()\n",
      "W[:,i].shape(3,)\n",
      "e.shape (3,)\n",
      "yi.shape ()\n",
      "W[:,i].shape(3,)\n",
      "e.shape (3,)\n",
      "yi.shape ()\n",
      "W[:,i].shape(3,)\n",
      "e.shape (3,)\n"
     ]
    }
   ],
   "source": [
    "k = 3\n",
    "xt = A[0,:]\n",
    "print(f'xt.shape {xt.shape}')\n",
    "for i in range(k):\n",
    "    yi = np.dot(W[:,i].T, xt)\n",
    "    print(f'yi.shape {yi.shape}')\n",
    "    d[i] = lamda*d[i] + yi\n",
    "    print(f'W[:,i].shape{W[:,i].shape}')\n",
    "    e = xt - (yi*W[:,i])\n",
    "    print(f'e.shape {e.shape}')\n",
    "    W[:,i] = W[:,i] + (1/d[i])*yi*e\n",
    "    xt = xt - yi*W[:,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def track_W(xt, W, d, k, lamda=1):\n",
    "    if W is None:\n",
    "        W = np.zeros((xt.shape[0], xt.shape[0]))\n",
    "        np.fill_diagonal(W, W.diagonal() + 1)\n",
    "        d = 0.01 * np.ones(xt.shape[0])\n",
    "    x = xt.copy()\n",
    "    Yt = np.zeros(xt.shape[0])\n",
    "    for i in range(k):\n",
    "        yi = np.dot(W[:,i].T, x)\n",
    "        d[i] = lamda*d[i] + yi**2\n",
    "        e = x - (yi*W[:,i])\n",
    "        W[:,i] = W[:,i] + (1/d[i])*yi*e\n",
    "        x = x - yi*W[:,i]\n",
    "        Yt[i] = yi\n",
    "    return W, d, Yt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "xt = A[0,:]\n",
    "t= 1\n",
    "W = None\n",
    "d = None\n",
    "k = 1\n",
    "lamda =1\n",
    "W, d, Yt = track_W(xt, W, d, k, lamda=1)\n",
    "E_est = np.zeros(xt.shape[0])\n",
    "E = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spirit_algorithm(xt, t, E, E_est, W, d, k, lamda=1, fE=0.95, FE=0.98):\n",
    "    W, d, Yt = track_W(xt, W, d, k, lamda)\n",
    "    E = (lamda*(t-1)*E + np.sum(xt**2)) / t\n",
    "    print(f'E {E}')\n",
    "    E_est[0:k] = (lamda*(t-1)*E_est[0:k] + Yt[0:k]**2)/t\n",
    "    E_k = np.sum(E_est[0:k])\n",
    "    print(f'E_k {E_k}')\n",
    "    print(f'(fE*E) {(fE*E)}')\n",
    "    print(f'(FE*E) {(FE*E)}')\n",
    "    if E_k < (fE*E):\n",
    "        k = k + 1\n",
    "        print('Update k = k+1')\n",
    "        spirit_algorithm(xt, t, E, E_est, W, d, k, lamda, fE=0.95, FE=0.98)\n",
    "    elif E_k > (FE*E):\n",
    "        k = k - 1\n",
    "    return E, E_est, W, d, k\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E 23.290729371748398\n",
      "E_k 10.43477788199636\n",
      "(fE*E) 22.126192903160977\n",
      "(FE*E) 22.824914784313428\n",
      "Update k = k+1\n",
      "E 23.290729371748398\n",
      "E_k 52.36478632209681\n",
      "(fE*E) 22.126192903160977\n",
      "(FE*E) 22.824914784313428\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(23.290729371748398,\n",
       " array([51.93065771,  0.43412862,  0.        ]),\n",
       " array([[0.54064871, 0.98771736, 0.        ],\n",
       "        [0.53581838, 1.        , 0.        ],\n",
       "        [0.26983056, 0.49224711, 1.        ]]),\n",
       " array([6.23754356e+01, 4.44128616e-01, 1.00000000e-02]),\n",
       " 2)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xt = A[0,:]\n",
    "t= 1\n",
    "W = None\n",
    "d = None\n",
    "k = 1\n",
    "lamda =1\n",
    "E_est = np.zeros(xt.shape[0])\n",
    "E = 0\n",
    "spirit_algorithm(xt, t, E, E_est, W, d, k, lamda, fE=0.95, FE=0.98)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
